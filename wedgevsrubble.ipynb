{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wedge vs Rubblestone Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25c332b9e30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "random.seed(47)\n",
    "np.random.seed(47)\n",
    "torch.manual_seed(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = True\n",
    "normalize = True\n",
    "\n",
    "method = \"Yaser's method\"\n",
    "n_attributes = 12\n",
    "K = 5\n",
    "\n",
    "INPUT_LAYER = 48\n",
    "INPUT_ATTRIBUTES_METHOD = \"Yaser's method\"\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 16\n",
    "\n",
    "if not augmented:\n",
    "    print(\"augmented is False, ignoring normalize, method, n_attributes and K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unnamed.1</th>\n",
       "      <th>Id_wall_facing_element</th>\n",
       "      <th>Id_stone_type</th>\n",
       "      <th>Vertices</th>\n",
       "      <th>Faces</th>\n",
       "      <th>Area</th>\n",
       "      <th>Convex_hull_volume</th>\n",
       "      <th>Oriented_bounding_box_volume</th>\n",
       "      <th>Center_x</th>\n",
       "      <th>Center_y</th>\n",
       "      <th>...</th>\n",
       "      <th>Flakiness</th>\n",
       "      <th>Sphericity</th>\n",
       "      <th>Mean_discrete_gaussian_curvature</th>\n",
       "      <th>Var_discrete_gaussian_curvature</th>\n",
       "      <th>Azimuth_longest</th>\n",
       "      <th>Elevation_longest</th>\n",
       "      <th>Azimuth_middle</th>\n",
       "      <th>Elevation_middle</th>\n",
       "      <th>Azimuth_shortest</th>\n",
       "      <th>Elevation_shortest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>880</td>\n",
       "      <td>Phaistos_UM1005_Socle_31_Wedge</td>\n",
       "      <td>Wedge</td>\n",
       "      <td>62</td>\n",
       "      <td>96</td>\n",
       "      <td>0.007876</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.498011</td>\n",
       "      <td>0.343761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864475</td>\n",
       "      <td>0.588857</td>\n",
       "      <td>2.532808</td>\n",
       "      <td>6.070731</td>\n",
       "      <td>65.532211</td>\n",
       "      <td>12.195591</td>\n",
       "      <td>8.613949</td>\n",
       "      <td>72.048735</td>\n",
       "      <td>26.071202</td>\n",
       "      <td>19.187490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122</td>\n",
       "      <td>Anavlochos Demargne terrace_Elevation_244_Wedge</td>\n",
       "      <td>Wedge</td>\n",
       "      <td>69</td>\n",
       "      <td>114</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-3.016569</td>\n",
       "      <td>0.201758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543187</td>\n",
       "      <td>0.760899</td>\n",
       "      <td>1.390594</td>\n",
       "      <td>2.984991</td>\n",
       "      <td>38.704729</td>\n",
       "      <td>62.962013</td>\n",
       "      <td>5.777196</td>\n",
       "      <td>28.887084</td>\n",
       "      <td>75.694453</td>\n",
       "      <td>47.553249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>968</td>\n",
       "      <td>Phaistos_UM901_MM IIIB Foundation_14_RubbleStone</td>\n",
       "      <td>RubbleStone</td>\n",
       "      <td>289</td>\n",
       "      <td>513</td>\n",
       "      <td>0.007952</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.495457</td>\n",
       "      <td>-0.518704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819860</td>\n",
       "      <td>0.610814</td>\n",
       "      <td>3.576002</td>\n",
       "      <td>21.155149</td>\n",
       "      <td>17.761279</td>\n",
       "      <td>62.909181</td>\n",
       "      <td>7.522540</td>\n",
       "      <td>28.064784</td>\n",
       "      <td>80.218623</td>\n",
       "      <td>23.697364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>734</td>\n",
       "      <td>Hagia_Triada_Muro_Laviosa_I Phase_45_Wedge</td>\n",
       "      <td>Wedge</td>\n",
       "      <td>258</td>\n",
       "      <td>467</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>3.626062</td>\n",
       "      <td>-0.074495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606624</td>\n",
       "      <td>0.739493</td>\n",
       "      <td>2.331775</td>\n",
       "      <td>11.976726</td>\n",
       "      <td>7.037591</td>\n",
       "      <td>10.574681</td>\n",
       "      <td>14.031368</td>\n",
       "      <td>79.096638</td>\n",
       "      <td>83.694963</td>\n",
       "      <td>32.142293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>386</td>\n",
       "      <td>\\Anavlochos Quartier de La forge Wall AN19-04-...</td>\n",
       "      <td>Wedge</td>\n",
       "      <td>601</td>\n",
       "      <td>1101</td>\n",
       "      <td>0.014498</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>-2.314442</td>\n",
       "      <td>-0.034493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845019</td>\n",
       "      <td>0.582354</td>\n",
       "      <td>5.887830</td>\n",
       "      <td>49.315872</td>\n",
       "      <td>88.580295</td>\n",
       "      <td>89.059055</td>\n",
       "      <td>6.619356</td>\n",
       "      <td>3.461018</td>\n",
       "      <td>81.117584</td>\n",
       "      <td>76.780028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unnamed.1                             Id_wall_facing_element Id_stone_type  \\\n",
       "0        880                     Phaistos_UM1005_Socle_31_Wedge         Wedge   \n",
       "1        122    Anavlochos Demargne terrace_Elevation_244_Wedge         Wedge   \n",
       "2        968   Phaistos_UM901_MM IIIB Foundation_14_RubbleStone   RubbleStone   \n",
       "3        734         Hagia_Triada_Muro_Laviosa_I Phase_45_Wedge         Wedge   \n",
       "4        386  \\Anavlochos Quartier de La forge Wall AN19-04-...         Wedge   \n",
       "\n",
       "   Vertices  Faces      Area  Convex_hull_volume  \\\n",
       "0        62     96  0.007876            0.000092   \n",
       "1        69    114  0.006150            0.000075   \n",
       "2       289    513  0.007952            0.000093   \n",
       "3       258    467  0.013649            0.000240   \n",
       "4       601   1101  0.014498            0.000205   \n",
       "\n",
       "   Oriented_bounding_box_volume  Center_x  Center_y  ...  Flakiness  \\\n",
       "0                      0.000173  0.498011  0.343761  ...   0.864475   \n",
       "1                      0.000180 -3.016569  0.201758  ...   0.543187   \n",
       "2                      0.000231  0.495457 -0.518704  ...   0.819860   \n",
       "3                      0.000616  3.626062 -0.074495  ...   0.606624   \n",
       "4                      0.000470 -2.314442 -0.034493  ...   0.845019   \n",
       "\n",
       "   Sphericity  Mean_discrete_gaussian_curvature  \\\n",
       "0    0.588857                          2.532808   \n",
       "1    0.760899                          1.390594   \n",
       "2    0.610814                          3.576002   \n",
       "3    0.739493                          2.331775   \n",
       "4    0.582354                          5.887830   \n",
       "\n",
       "   Var_discrete_gaussian_curvature  Azimuth_longest  Elevation_longest  \\\n",
       "0                         6.070731        65.532211          12.195591   \n",
       "1                         2.984991        38.704729          62.962013   \n",
       "2                        21.155149        17.761279          62.909181   \n",
       "3                        11.976726         7.037591          10.574681   \n",
       "4                        49.315872        88.580295          89.059055   \n",
       "\n",
       "   Azimuth_middle  Elevation_middle  Azimuth_shortest  Elevation_shortest  \n",
       "0        8.613949         72.048735         26.071202           19.187490  \n",
       "1        5.777196         28.887084         75.694453           47.553249  \n",
       "2        7.522540         28.064784         80.218623           23.697364  \n",
       "3       14.031368         79.096638         83.694963           32.142293  \n",
       "4        6.619356          3.461018         81.117584           76.780028  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataframes = []#[pd.read_excel(\"shuffled_data.ods\", engine=\"odf\")]\n",
    "#dataframes[-1][\"Id_stone_type\"] = dataframes[-1][\"Id_stone_type\"].map(lambda s: 0 if s == \"Wedge\" else 1)\n",
    "\n",
    "for k in range(K):\n",
    "    if augmented:\n",
    "        filename = \"datasets/augmented m({}) a({}) k({}){}.ods\".format(method, n_attributes, k + 1, (\" N\" if normalize else \"\"))\n",
    "    else:\n",
    "        filename = \"datasets/k({}).ods\".format(k + 1)\n",
    "        \n",
    "    dataframes.append(pd.read_excel(filename, engine=\"odf\"))\n",
    "    dataframes[-1][\"Id_stone_type\"] = dataframes[-1][\"Id_stone_type\"].map(lambda s: 0 if s == \"Wedge\" else 1)\n",
    "\n",
    "\"\"\"\n",
    "dataframe = pd.read_excel(\"data.ods\", engine=\"odf\")\n",
    "wedge,rubble = 0,0\n",
    "for type in dataframe[\"Id_stone_type\"]:\n",
    "    if type == \"Wedge\":\n",
    "        wedge += 1\n",
    "    elif type == \"RubbleStone\":\n",
    "        rubble += 1\n",
    "print(wedge, rubble)\n",
    "dataframe[\"Id_stone_type\"] = dataframe[\"Id_stone_type\"].map(lambda s: 0 if s == \"Wedge\" else 1)\n",
    "dataframe.head(5)\n",
    "\"\"\"\n",
    "\n",
    "pd.read_excel(\"shuffled_data.ods\", engine=\"odf\").head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_ATTRIBUTES = {\"random\" : random.choices(list(range(3, 51)), k = 48),\n",
    "           \"average threshold\" :  [37, 7, 39, 5, 6, 25, 26, 13, 23, 3, 38, 4, 44, 21, 22, 11, 24, 20, 43, 36, 12, 9, 40, 19, 33, 48, 49, 18, 32, 41, 35, 50, 45, 15, 27, 14, 28, 34, 47, 30, 42, 29, 8, 46, 17, 10, 31, 16], \n",
    "           \"maximizer threshold\": [37, 5, 7, 39, 6, 36, 3, 4, 38, 25, 21, 26, 23, 24, 20, 22, 44, 43, 12, 13, 17, 18, 27, 28, 29, 32, 33, 34, 35, 40, 46, 48, 49, 50, 11, 41, 8, 9, 10, 14, 15, 16, 19, 30, 31, 42, 45, 47],\n",
    "           \"Yaser's method\" :     [37, 9, 40, 4, 3, 48, 8, 23, 17, 32, 25, 18, 29, 5, 11, 38, 13, 50, 16, 10, 26, 6, 21, 7, 24, 46, 28, 19, 39, 43, 36, 14, 15, 22, 34, 42, 33, 45, 44, 31, 20, 47, 30, 49, 41, 35, 27, 12],\n",
    "           \"chi2 n2\" :            [3, 4, 5, 6, 7, 39, 44, 43, 37, 20, 36, 24, 11, 21, 25, 26, 22, 23, 13, 12, 41, 38, 9, 42, 15, 18, 27, 49, 45, 10, 46, 48, 17, 16, 31, 34, 35, 30, 47, 40, 50, 14, 19, 32, 28, 29, 33, 8],\n",
    "           \"chi2 n4\" :            [44, 6, 7, 39, 5, 3, 4, 43, 36, 37, 9, 20, 25, 22, 12, 24, 13, 11, 23, 21, 26, 38, 41, 10, 49, 15, 27, 16, 42, 8, 45, 18, 19, 14, 17, 46, 34, 28, 33, 31, 35, 48, 40, 30, 32, 29, 50, 47],     \n",
    "           \"chi2 n8\" :            [44, 6, 7, 39, 4, 3, 5, 43, 9, 36, 37, 20, 25, 12, 22, 21, 13, 24, 11, 23, 26, 38, 27, 41, 15, 49, 10, 34, 14, 16, 8, 45, 42, 33, 28, 19, 18, 17, 32, 46, 31, 35, 48, 40, 29, 30, 50, 47],\n",
    "           \"chi2 n16\" :           [44, 6, 7, 39, 4, 3, 5, 43, 9, 37, 36, 24, 20, 25, 13, 22, 11, 12, 21, 23, 26, 27, 38, 41, 34, 49, 10, 14, 8, 15, 16, 42, 45, 32, 33, 28, 18, 19, 17, 46, 31, 35, 48, 29, 40, 30, 50, 47],\n",
    "           \"chi2 n32\" :           [44, 6, 7, 39, 4, 3, 5, 43, 9, 37, 36, 12, 24, 20, 22, 13, 25, 11, 27, 21, 23, 26, 38, 34, 41, 8, 49, 10, 14, 15, 42, 16, 32, 45, 33, 28, 19, 18, 17, 46, 31, 35, 29, 48, 30, 40, 50, 47],\n",
    "           \"chi2 n64\" :           [44, 6, 7, 39, 4, 3, 5, 9, 43, 37, 36, 12, 24, 20, 22, 25, 27, 13, 11, 21, 23, 26, 38, 34, 41, 8, 49, 10, 15, 14, 42, 16, 32, 45, 33, 28, 18, 19, 46, 17, 31, 35, 29, 30, 48, 40, 50, 47]\n",
    "}\n",
    "\n",
    "class StoneDataset(Dataset): #impolementare len e get item\n",
    "    def __init__(self, dataframe, train = True, train_size = None, transforms = None, k = 0):\n",
    "        super(Dataset, self).__init__()\n",
    "        #train_size = round(train_size * len(dataframe))\n",
    "        self.transforms = transforms\n",
    "        #top_attributes = [37, 7, 39, 5, 6, 25, 26, 13, 23, 3, 38, 4] #trovati con tresh = average\n",
    "        #top_attributes = [37, 5, 7, 39, 6, 36, 3, 4, 38, 25, 21, 26] #trovati con ricerca di tresh\n",
    "        \n",
    "        if train:\n",
    "            #self.data = dataframe.iloc[:train_size, 3:]      #all attributes\n",
    "            self.data = dataframe.iloc[:train_size, TOP_ATTRIBUTES[INPUT_ATTRIBUTES_METHOD][:INPUT_LAYER]]\n",
    "            _targets = dataframe.iloc[:train_size, 2]\n",
    "            \n",
    "            #self.data = dataframe.iloc[:train_size, top_attributes]\n",
    "            #print(self.data)\n",
    "            _targets = dataframe.iloc[:train_size, 2]\n",
    "        else:\n",
    "            self.data = dataframe.iloc[train_size:, 3:]      #all attributes\n",
    "            self.data = dataframe.iloc[train_size:, TOP_ATTRIBUTES[INPUT_ATTRIBUTES_METHOD][:INPUT_LAYER]]\n",
    "            _targets = dataframe.iloc[train_size:, 2]\n",
    "\n",
    "            #self.data = dataframe.iloc[train_size:, top_attributes]\n",
    "            #_targets = dataframe.iloc[train_size:, 2]\n",
    "        \n",
    "        self.data = self.data.to_numpy()\n",
    "        #self.targets = np.zeros((len(self.data), 2))\n",
    "        #self.targets[:, 0] = _targets\n",
    "        #self.targets[:, 1] = 1 - self.targets[:, 0]\n",
    "\n",
    "        #print(self.targets)\n",
    "        \n",
    "        # to tensor\n",
    "        self.data = torch.tensor(self.data, dtype = torch.float32)\n",
    "        print(\"_targets.to_numpy:\", _targets.to_numpy())\n",
    "        self.targets = torch.stack(tuple([torch.tensor(_targets.to_numpy(), dtype = torch.float32)]))\n",
    "        \n",
    "        #self.targets = torch.tensor(self.targets, dtype = torch.float32).T\n",
    "\n",
    "        print(self.targets.shape)\n",
    "\n",
    "        #if transforms != None: TODO\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        if self.transforms:\n",
    "            return self.transforms(self.data[i]), self.targets[:,i]\n",
    "        return self.data[i], self.targets[:,i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network class\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.linear1 = nn.Linear(INPUT_LAYER, 128)\n",
    "        self.linear2 = nn.Linear(128, 64)\n",
    "        self.linear3 = nn.Linear(64 + INPUT_LAYER, 1) # 64 + INPUT_LAYER for skip connection\n",
    "\n",
    "        self.dp1 = nn.Dropout(p = 0.5)\n",
    "        self.dp2 = nn.Dropout(p = 0.4)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = self.linear1(inp)\n",
    "        x = F.leaky_relu(x, negative_slope = 0.05)  #F.tanh\n",
    "        x = self.dp1(x)\n",
    "\n",
    "        x = self.linear2(x)\n",
    "        x = F.leaky_relu(x, negative_slope = 0.05)\n",
    "        x = self.dp2(x)\n",
    "\n",
    "        x = self.linear3(torch.cat([x, inp], dim = 1)) #skip connection\n",
    "        #x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training class\n",
    "class ClassifierLightning(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(ClassifierLightning, self).__init__()\n",
    "        self.model = Classifier()\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def accuracy(self, y_hat, y): #y = expected\n",
    "        return torch.where(((y_hat>0) == y),1.0,0.0).sum()/BATCH_SIZE\n",
    "        y_hat = torch.where(F.sigmoid(y_hat) > 0.5, 1.0, 0.0)\n",
    "        return torch.sum(torch.argmax(y_hat, dim = 0) == y).item()/y.shape[0]\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(params = self.parameters(), lr = 5e-4, weight_decay = 3e-5)  #lr = 5e-4 * 1.2 con scheduler else 3e-4\n",
    "        scheduler = StepLR(optimizer, step_size=32, gamma=0.8)\n",
    "        #optimizer = SGD(params = self.parameters(), lr = 0.02, momentum = 0.9, weight_decay = 1e-5) #nesterov\n",
    "        return [optimizer], [scheduler] #usare se c'Ã¨ lo scheduler\n",
    "        return optimizer                #altrimenti\n",
    "\n",
    "    def training_step(self, train_batch, batch_id):\n",
    "        self.model.train()\n",
    "        x, y = train_batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        accuracy = self.accuracy(logits, y)\n",
    "        self.log(\"train_accuracy\", accuracy)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_id):\n",
    "        self.model.eval()\n",
    "        x, y = val_batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        accuracy = self.accuracy(logits, y)\n",
    "        self.log(\"val_accuracy\", accuracy)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu available: True\n",
      "device count: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"gpu available:\", torch.cuda.is_available())\n",
    "print(\"device count:\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_targets.to_numpy: [0 1 1 ... 0 1 1]\n",
      "torch.Size([1, 1949])\n",
      "_targets.to_numpy: [1 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 0 1 1 0\n",
      " 1 1 0 1 1 0 0 0 1 1 1 0 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1\n",
      " 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0\n",
      " 1 0 0 1 0 0 1 0 1 0 0 1 1 1]\n",
      "torch.Size([1, 162])\n",
      "train size: 1949\n",
      "val size: 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params\n",
      "------------------------------------------------\n",
      "0 | model     | Classifier        | 14.6 K\n",
      "1 | criterion | BCEWithLogitsLoss | 0     \n",
      "------------------------------------------------\n",
      "14.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.6 K    Total params\n",
      "0.059     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:00<00:00, 225.70it/s, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=16` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:00<00:00, 223.23it/s, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_targets.to_numpy: [1 1 1 ... 0 1 1]\n",
      "torch.Size([1, 1949])\n",
      "_targets.to_numpy: [0 1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1\n",
      " 0 0 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1\n",
      " 0 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 1 0 1\n",
      " 0 1 1 0 0 1 1 0 0 1 1 1 0 0]\n",
      "torch.Size([1, 162])\n",
      "train size: 1949\n",
      "val size: 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params\n",
      "------------------------------------------------\n",
      "0 | model     | Classifier        | 14.6 K\n",
      "1 | criterion | BCEWithLogitsLoss | 0     \n",
      "------------------------------------------------\n",
      "14.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.6 K    Total params\n",
      "0.059     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:00<00:00, 189.48it/s, v_num=1]       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=16` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:00<00:00, 187.45it/s, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_targets.to_numpy: [1 1 1 ... 0 1 1]\n",
      "torch.Size([1, 1949])\n",
      "_targets.to_numpy: [0 1 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 1 1 0\n",
      " 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 1\n",
      " 1 0 0 0 0 1 0 0 1 1 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 0 0 0 0 0\n",
      " 0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 1 1 1\n",
      " 0 0 0 0 1 1 0 0 0 0 1 1 0 1]\n",
      "torch.Size([1, 162])\n",
      "train size: 1949\n",
      "val size: 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params\n",
      "------------------------------------------------\n",
      "0 | model     | Classifier        | 14.6 K\n",
      "1 | criterion | BCEWithLogitsLoss | 0     \n",
      "------------------------------------------------\n",
      "14.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.6 K    Total params\n",
      "0.059     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:00<00:00, 186.46it/s, v_num=1]       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=16` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:00<00:00, 185.05it/s, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_targets.to_numpy: [1 1 1 ... 0 1 1]\n",
      "torch.Size([1, 1949])\n",
      "_targets.to_numpy: [1 1 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 1 0 0 1 1 0 0\n",
      " 1 0 1 0 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 0\n",
      " 0 0 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 1 1 1 0 1 0 1 0\n",
      " 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 1\n",
      " 0 0 0 0 1 1 1 0 1 1 0 0 1 0]\n",
      "torch.Size([1, 162])\n",
      "train size: 1949\n",
      "val size: 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params\n",
      "------------------------------------------------\n",
      "0 | model     | Classifier        | 14.6 K\n",
      "1 | criterion | BCEWithLogitsLoss | 0     \n",
      "------------------------------------------------\n",
      "14.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.6 K    Total params\n",
      "0.059     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:00<00:00, 211.78it/s, v_num=1]       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=16` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:00<00:00, 209.97it/s, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_targets.to_numpy: [1 1 1 ... 0 1 1]\n",
      "torch.Size([1, 1949])\n",
      "_targets.to_numpy: [1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0 0 1 1 0 1 1 0\n",
      " 0 1 1 0 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 1 1 1\n",
      " 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1\n",
      " 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 1 0 1 0 0 1 0 1 1 0\n",
      " 0 1 1 0 1 1 0 0 0 1 0 1 0 0]\n",
      "torch.Size([1, 162])\n",
      "train size: 1949\n",
      "val size: 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type              | Params\n",
      "------------------------------------------------\n",
      "0 | model     | Classifier        | 14.6 K\n",
      "1 | criterion | BCEWithLogitsLoss | 0     \n",
      "------------------------------------------------\n",
      "14.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "14.6 K    Total params\n",
      "0.059     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:00<00:00, 200.94it/s, v_num=1]       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=16` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:00<00:00, 198.98it/s, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Lambda\n",
    "\n",
    "transform = Lambda(lambda x: x + torch.randn_like(x)*0.04)\n",
    "for k in range(K):\n",
    "    #creating train & validation sets\n",
    "    train_set = StoneDataset(dataframes[k], train = True, train_size = len(dataframes[k]) - 813//K, transforms = transform) #813 = len of original dataset\n",
    "    val_set = StoneDataset(dataframes[k], train = False, train_size = len(dataframes[k]) - 813//K)\n",
    "\n",
    "    #loading sets\n",
    "    train_loader = DataLoader(dataset = train_set, batch_size = BATCH_SIZE, shuffle = True)\n",
    "    val_loader = DataLoader(dataset = val_set, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "    #prendere un numero di feature a caso e azzerarle (?)\n",
    "\n",
    "    print(\"train size:\", len(train_set))\n",
    "    print(\"val size:\", len(val_set))\n",
    "\n",
    "    name = \"augmented m({}) a({}) k({}){} i({}) im({})\".format(method, n_attributes, k + 1, (\" N\" if normalize else \"\"), INPUT_LAYER, INPUT_ATTRIBUTES_METHOD) if augmented else \"k({}) i({}) im({})\".format(k + 1, INPUT_LAYER, INPUT_ATTRIBUTES_METHOD)\n",
    "\n",
    "    logger = pl.loggers.TensorBoardLogger(\"logs\", name = (\"augmented m({}) a({}) k({}){} i({}) im({})\".format(method, n_attributes, k + 1, (\" N\" if normalize else \"\"), INPUT_LAYER, INPUT_ATTRIBUTES_METHOD) if augmented else \"k({}) i({}) im({})\".format(k + 1, INPUT_LAYER, INPUT_ATTRIBUTES_METHOD)))#, version = (\"augmented m({}) a({}) k({}){}\".format(method, n_attributes, k + 1, (\" N\" if normalize else \"\")) if augmented else \"k({}) i({}) im({})\".format(k + 1, INPUT_LAYER, INPUT_ATTRIBUTES_METHOD)) )\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    trainer = pl.Trainer(max_epochs = EPOCHS, logger = logger, accelerator = \"gpu\", devices = 1)\n",
    "    model = ClassifierLightning().to(device)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    #save model\n",
    "    torch.save(model.state_dict(), \"models/\" + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.9664e+00],\n",
      "        [-4.1717e+00],\n",
      "        [-5.2214e-01],\n",
      "        [ 3.0706e+00],\n",
      "        [ 1.2139e+00],\n",
      "        [-3.5771e-01],\n",
      "        [-2.1183e+00],\n",
      "        [ 2.6912e+00],\n",
      "        [-1.2913e-01],\n",
      "        [ 8.7450e+00],\n",
      "        [ 4.9046e-01],\n",
      "        [-3.3906e+00],\n",
      "        [ 6.9685e+00],\n",
      "        [-2.5793e+00],\n",
      "        [-8.5209e-01],\n",
      "        [ 3.6390e-01],\n",
      "        [ 5.1519e+00],\n",
      "        [ 2.0386e+00],\n",
      "        [-1.0543e+00],\n",
      "        [ 3.1870e+00],\n",
      "        [-2.4056e+00],\n",
      "        [ 5.0588e+00],\n",
      "        [-8.9132e-01],\n",
      "        [ 4.7143e+00],\n",
      "        [ 1.2652e+00],\n",
      "        [-5.3037e-01],\n",
      "        [-2.1218e+00],\n",
      "        [-4.0711e+00],\n",
      "        [ 1.5076e+00],\n",
      "        [-3.8185e+00],\n",
      "        [-1.3815e+00],\n",
      "        [ 5.9051e+00],\n",
      "        [ 3.3784e+00],\n",
      "        [-5.2965e+00],\n",
      "        [ 6.6588e+00],\n",
      "        [-7.2060e-01],\n",
      "        [ 2.7523e-01],\n",
      "        [-1.6632e+00],\n",
      "        [ 1.9011e+01],\n",
      "        [ 1.1300e+00],\n",
      "        [ 2.4853e+00],\n",
      "        [-4.1008e+00],\n",
      "        [-4.8939e+00],\n",
      "        [-4.5064e+00],\n",
      "        [-5.3371e+00],\n",
      "        [ 1.5327e+00],\n",
      "        [-2.4958e-01],\n",
      "        [ 1.0440e+00],\n",
      "        [ 2.1978e-01],\n",
      "        [ 6.8951e-01],\n",
      "        [ 1.1136e-02],\n",
      "        [-1.1855e+00],\n",
      "        [ 4.2275e-01],\n",
      "        [-5.8010e+00],\n",
      "        [ 6.2245e-01],\n",
      "        [-3.9319e+00],\n",
      "        [-1.2810e+00],\n",
      "        [ 2.9339e+00],\n",
      "        [ 3.6250e+00],\n",
      "        [-8.8574e+00],\n",
      "        [ 3.3581e+00],\n",
      "        [ 8.8861e+00],\n",
      "        [ 2.9398e+00],\n",
      "        [-2.5639e+00]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    input = torch.stack([val_set[i][0] for i in range(64)])\n",
    "    print(model(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7901)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m acc \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(val_set)):\n\u001b[0;32m     10\u001b[0m     \u001b[39m#print(model(val_set[i][0]), val_set[i][1])\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[39m#if (model( torch.stack([val_set[i][0]]) ) > 0) == val_set[i][1]:  #skip connection\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     \u001b[39mif\u001b[39;00m (model(val_set[i][\u001b[39m0\u001b[39;49m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m val_set[i][\u001b[39m1\u001b[39m]: \n\u001b[0;32m     13\u001b[0m         acc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[39mprint\u001b[39m(acc\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(val_set))\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m, in \u001b[0;36mClassifierLightning.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 15\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n",
      "File \u001b[1;32mc:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m, in \u001b[0;36mClassifier.forward\u001b[1;34m(self, inp)\u001b[0m\n\u001b[0;32m     18\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mleaky_relu(x, negative_slope \u001b[39m=\u001b[39m \u001b[39m0.05\u001b[39m)\n\u001b[0;32m     19\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdp2(x)\n\u001b[1;32m---> 21\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear3(torch\u001b[39m.\u001b[39;49mcat([x, inp], dim \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)) \u001b[39m#skip connection\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m#x = self.linear3(x)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    acc = 0\n",
    "    for x,y in iter(val_loader):\n",
    "        acc += torch.where(((model(x)>0) == y),1.0,0.0).sum()\n",
    "    print(acc/len(val_set))\n",
    "\n",
    "    acc = 0\n",
    "    for i in range(len(val_set)):\n",
    "        #print(model(val_set[i][0]), val_set[i][1])\n",
    "        #if (model( torch.stack([val_set[i][0]]) ) > 0) == val_set[i][1]:  #skip connection\n",
    "        if (model(val_set[i][0]) > 0) == val_set[i][1]: \n",
    "            acc += 1\n",
    "    print(acc/len(val_set))\n",
    "\n",
    "    acc = 0\n",
    "    for i in range(len(train_set)):\n",
    "        #print(model(val_set[i][0]), val_set[i][1])\n",
    "        #if (model( torch.stack([train_set[i][0]]) ) > 0) == train_set[i][1]: #skip connection\n",
    "        if (model(train_set[i][0]) > 0) == train_set[i][1]: \n",
    "            acc += 1\n",
    "    print(\"train acc\", acc/len(train_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
